# prompt-Engineering

# ChatGPT Prompt Engineering Course Introduction

**Welcome to the ChatGPT Prompt Engineering for Developers Course!**

## **Course Overview:**
In this course, we aim to shift the focus from the commonly explored chatGPT web interface to the potential of LLMs as a powerful developer tool. We'll explore how API calls to LLMs can rapidly facilitate the creation of software applications. The course will cover prompting best practices, common use cases such as summarizing, inferring, transforming, and expanding, and culminate in building a chatbot using an LLM.

## **Types of LLMs:**
### 1. Base LLMs:
- Trained to predict the next word based on extensive text training data.
- Example: Given the prompt "Once upon a time there was a unicorn," it might predict, "that live in a magical forest with all unicorn friends."

### 2. Instruction-Tuned LLMs:
- Trained to follow instructions, making them highly practical for various applications.
- Typically refined using reinforcement learning from human feedback (RLHF).
- Emphasizes helpful, honest, and harmless outputs, reducing the likelihood of problematic text.

## **Best Practices:**
- **Focus on Instruction-Tuned LLMs:** Due to their safety and alignment, instruction-tuned LLMs are recommended for most practical applications.


## **Working with Instruction-Tuned LLMs:**
- Treat the LLM as if instructing a smart but task-unfamiliar person.
- Clarify instructions for optimal results, specifying focus, tone, and any necessary context.
- Provide guidelines akin to instructing a fresh college graduate, enhancing the chances of successful task completion.


Let's embark on this exciting journey into ChatGPT Prompt Engineering!
